{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, LSTM, SimpleRNN, GRU, Bidirectional\n",
    "from tensorflow.keras.models import save_model \n",
    "\n",
    "nltk.data.path.append(\"D:\\\\Environment\\\\nltk_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reading/cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45905</td>\n",
       "      <td>Exclusive: Foreign Isis Fighters Defend Mosul ...</td>\n",
       "      <td>\\nForeign fighters for Isis are choosing to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37291</td>\n",
       "      <td>JUDGE JEANINE UNLOADS On Hillary: “How Did You...</td>\n",
       "      <td>You don t want to miss a second of Judge Jeani...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46730</td>\n",
       "      <td>Gunman attacks Saudi security forces at gate o...</td>\n",
       "      <td>RIYADH (Reuters) - Two Saudi guards were shot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66327</td>\n",
       "      <td>Indian Software Mogul: Hire Americans Now Beca...</td>\n",
       "      <td>A leading Indian software entrepreneur says In...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58329</td>\n",
       "      <td>Rep. Diaz-Balart: Liberals Against Trump Who F...</td>\n",
       "      <td>Florida Congressman Mario   attacked the “doub...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0       45905  Exclusive: Foreign Isis Fighters Defend Mosul ...   \n",
       "1       37291  JUDGE JEANINE UNLOADS On Hillary: “How Did You...   \n",
       "2       46730  Gunman attacks Saudi security forces at gate o...   \n",
       "3       66327  Indian Software Mogul: Hire Americans Now Beca...   \n",
       "4       58329  Rep. Diaz-Balart: Liberals Against Trump Who F...   \n",
       "\n",
       "                                                text  label  \n",
       "0    \\nForeign fighters for Isis are choosing to ...      1  \n",
       "1  You don t want to miss a second of Judge Jeani...      1  \n",
       "2  RIYADH (Reuters) - Two Saudi guards were shot ...      0  \n",
       "3  A leading Indian software entrepreneur says In...      0  \n",
       "4  Florida Congressman Mario   attacked the “doub...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/WELFake_clean_train.csv')\n",
    "df_test = pd.read_csv('../data/WELFake_clean_test.csv')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50990</td>\n",
       "      <td>BLM Rapper &amp; Bill’s Alleged Son Have Nasty Sur...</td>\n",
       "      <td>BLM Rapper &amp; Bill’s Alleged Son Have Nasty Sur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41146</td>\n",
       "      <td>US Airstrike Killed Five Al-Qaeda Members in Y...</td>\n",
       "      <td>Get short URL 0 2 0 0 The US military killed f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48389</td>\n",
       "      <td>Zach Johnson, Pieters share lead at Firestone</td>\n",
       "      <td>(Reuters) - Late birdies from Thomas Pieters a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55759</td>\n",
       "      <td>Re: WOW! What Josh Earnest admitted about Obam...</td>\n",
       "      <td>WOW! What Josh Earnest admitted about Obamacar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21412</td>\n",
       "      <td>Memorial Day provides respite from VA controve...</td>\n",
       "      <td>Memorial Day is a time to remember those who g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0       50990  BLM Rapper & Bill’s Alleged Son Have Nasty Sur...   \n",
       "1       41146  US Airstrike Killed Five Al-Qaeda Members in Y...   \n",
       "2       48389      Zach Johnson, Pieters share lead at Firestone   \n",
       "3       55759  Re: WOW! What Josh Earnest admitted about Obam...   \n",
       "4       21412  Memorial Day provides respite from VA controve...   \n",
       "\n",
       "                                                text  label  \n",
       "0  BLM Rapper & Bill’s Alleged Son Have Nasty Sur...      1  \n",
       "1  Get short URL 0 2 0 0 The US military killed f...      1  \n",
       "2  (Reuters) - Late birdies from Thomas Pieters a...      0  \n",
       "3  WOW! What Josh Earnest admitted about Obamacar...      1  \n",
       "4  Memorial Day is a time to remember those who g...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove special characters and numbers\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        exclusive foreign isi fighter defend mosul fro...\n",
       "1        judge jeanine unloads hillary go dead broke wo...\n",
       "2        gunman attack saudi security force gate jeddah...\n",
       "3        indian software mogul hire american trump oppo...\n",
       "4        rep diazbalart liberal trump favored obamas cu...\n",
       "                               ...                        \n",
       "56629    applause boo kerry urge congress ratify pacifi...\n",
       "56630    tingle leg nbc paid chris matthew staffer sexu...\n",
       "56631    u government share technical detail north kore...\n",
       "56632    trump history corruption mindboggling clinton ...\n",
       "56633    facezam app let stranger stalk facebook profil...\n",
       "Name: joined, Length: 56634, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['title'] = df_train['title'].apply(clean_text)\n",
    "df_train['text'] = df_train['text'].apply(clean_text)\n",
    "df_test['title'] = df_test['title'].apply(clean_text)\n",
    "df_test['text'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "df_train['title'] = df_train['title'].apply(word_tokenize)\n",
    "df_train['text'] = df_train['text'].apply(word_tokenize)\n",
    "df_test['title'] = df_test['title'].apply(word_tokenize)\n",
    "df_test['text'] = df_test['text'].apply(word_tokenize)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_train['title'] = df_train['title'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df_train['text'] = df_train['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df_test['title'] = df_test['title'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df_test['text'] = df_test['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_train['title'] = df_train['title'].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "df_train['text'] = df_train['text'].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "df_test['title'] = df_test['title'].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "df_test['text'] = df_test['text'].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "\n",
    "df_train['joined'] = df_train['title'].apply(lambda x: ' '.join(x)) + ' ' + df_train['text'].apply(lambda x: ' '.join(x))\n",
    "df_test['joined'] = df_test['title'].apply(lambda x: ' '.join(x)) + ' ' + df_test['text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "X_train = df_train['joined']\n",
    "y_train = df_train['label']\n",
    "X_test = df_test['joined']\n",
    "y_test = df_test['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Machine Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9538809237940532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      6907\n",
      "           1       0.95      0.96      0.96      7252\n",
      "\n",
      "    accuracy                           0.95     14159\n",
      "   macro avg       0.95      0.95      0.95     14159\n",
      "weighted avg       0.95      0.95      0.95     14159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = train_logistic_regression(X_train_tfidf, y_train)\n",
    "evaluate_model(lr_model, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(X_train, y_train):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8529557172116675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      6907\n",
      "           1       0.85      0.87      0.86      7252\n",
      "\n",
      "    accuracy                           0.85     14159\n",
      "   macro avg       0.85      0.85      0.85     14159\n",
      "weighted avg       0.85      0.85      0.85     14159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = train_naive_bayes(X_train_tfidf, y_train)\n",
    "evaluate_model(nb_model, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train):\n",
    "    model = SVC(kernel='linear', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Environment\\anaconda\\envs\\deepmachinelearning\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8973091320008475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      6907\n",
      "           1       0.91      0.89      0.90      7252\n",
      "\n",
      "    accuracy                           0.90     14159\n",
      "   macro avg       0.90      0.90      0.90     14159\n",
      "weighted avg       0.90      0.90      0.90     14159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = train_svm(X_train_tfidf, y_train)\n",
    "evaluate_model(svm_model, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=44)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954163429620736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      6907\n",
      "           1       0.95      0.96      0.96      7252\n",
      "\n",
      "    accuracy                           0.95     14159\n",
      "   macro avg       0.95      0.95      0.95     14159\n",
      "weighted avg       0.95      0.95      0.95     14159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = train_random_forest(X_train_tfidf, y_train)\n",
    "evaluate_model(rf_model, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "maxlen = 500\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=maxlen))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "    return model\n",
    "\n",
    "def evaluate_dl_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "708/708 [==============================] - 10s 6ms/step - loss: 0.1855 - accuracy: 0.9224 - val_loss: 0.0936 - val_accuracy: 0.9659\n",
      "Epoch 2/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0510 - accuracy: 0.9830 - val_loss: 0.0982 - val_accuracy: 0.9666\n",
      "Epoch 3/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.1812 - val_accuracy: 0.9560\n",
      "Epoch 4/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1801 - val_accuracy: 0.9660\n",
      "Epoch 5/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1990 - val_accuracy: 0.9642\n",
      "Epoch 6/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1889 - val_accuracy: 0.9670\n",
      "Epoch 7/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1999 - val_accuracy: 0.9674\n",
      "Epoch 8/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.2838 - val_accuracy: 0.9622\n",
      "Epoch 9/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.2345 - val_accuracy: 0.9656\n",
      "Epoch 10/10\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.2158 - val_accuracy: 0.9656\n",
      "Accuracy: 0.9653224097747016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      6907\n",
      "           1       0.97      0.97      0.97      7252\n",
      "\n",
      "    accuracy                           0.97     14159\n",
      "   macro avg       0.97      0.97      0.97     14159\n",
      "weighted avg       0.97      0.97      0.97     14159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_model = train_cnn(X_train_pad, y_train)\n",
    "evaluate_dl_model(cnn_model, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=maxlen))\n",
    "    model.add(SimpleRNN(128))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "708/708 [==============================] - 294s 415ms/step - loss: 0.3868 - accuracy: 0.8169 - val_loss: 0.3986 - val_accuracy: 0.8104\n",
      "Epoch 2/10\n",
      "708/708 [==============================] - 282s 398ms/step - loss: 0.2940 - accuracy: 0.8727 - val_loss: 0.2450 - val_accuracy: 0.9023\n",
      "Epoch 3/10\n",
      "708/708 [==============================] - 288s 407ms/step - loss: 0.2828 - accuracy: 0.8811 - val_loss: 0.3157 - val_accuracy: 0.8700\n",
      "Epoch 4/10\n",
      "708/708 [==============================] - 223s 314ms/step - loss: 0.2437 - accuracy: 0.9019 - val_loss: 0.3034 - val_accuracy: 0.8899\n",
      "Epoch 5/10\n",
      "708/708 [==============================] - 253s 358ms/step - loss: 0.1988 - accuracy: 0.9252 - val_loss: 0.2598 - val_accuracy: 0.9054\n",
      "Epoch 6/10\n",
      "708/708 [==============================] - 236s 334ms/step - loss: 0.1468 - accuracy: 0.9488 - val_loss: 0.2511 - val_accuracy: 0.9096\n",
      "Epoch 7/10\n",
      "708/708 [==============================] - 230s 326ms/step - loss: 0.1286 - accuracy: 0.9563 - val_loss: 0.2718 - val_accuracy: 0.9039\n",
      "Epoch 8/10\n",
      "708/708 [==============================] - 228s 323ms/step - loss: 0.1158 - accuracy: 0.9599 - val_loss: 0.2900 - val_accuracy: 0.9099\n",
      "Epoch 9/10\n",
      "708/708 [==============================] - 215s 304ms/step - loss: 0.1729 - accuracy: 0.9317 - val_loss: 0.2650 - val_accuracy: 0.9080\n",
      "Epoch 10/10\n",
      "708/708 [==============================] - 220s 310ms/step - loss: 0.1882 - accuracy: 0.9253 - val_loss: 0.3232 - val_accuracy: 0.8682\n",
      "Accuracy: 0.8565576665018716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87      6907\n",
      "           1       0.93      0.77      0.85      7252\n",
      "\n",
      "    accuracy                           0.86     14159\n",
      "   macro avg       0.87      0.86      0.86     14159\n",
      "weighted avg       0.87      0.86      0.86     14159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_model = train_rnn(X_train_pad, y_train)\n",
    "evaluate_dl_model(rnn_model, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=maxlen))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "708/708 [==============================] - 27s 36ms/step - loss: 0.2619 - accuracy: 0.8959 - val_loss: 0.2490 - val_accuracy: 0.8947\n",
      "Epoch 2/10\n",
      "708/708 [==============================] - 24s 33ms/step - loss: 0.1383 - accuracy: 0.9491 - val_loss: 0.1511 - val_accuracy: 0.9433\n",
      "Epoch 3/10\n",
      "708/708 [==============================] - 24s 34ms/step - loss: 0.0914 - accuracy: 0.9676 - val_loss: 0.1567 - val_accuracy: 0.9470\n",
      "Epoch 4/10\n",
      "708/708 [==============================] - 24s 34ms/step - loss: 0.1330 - accuracy: 0.9479 - val_loss: 0.1098 - val_accuracy: 0.9620\n",
      "Epoch 5/10\n",
      "708/708 [==============================] - 24s 34ms/step - loss: 0.0373 - accuracy: 0.9868 - val_loss: 0.1444 - val_accuracy: 0.9564\n",
      "Epoch 6/10\n",
      "708/708 [==============================] - 24s 34ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.1238 - val_accuracy: 0.9663\n",
      "Epoch 7/10\n",
      "708/708 [==============================] - 24s 33ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1530 - val_accuracy: 0.9635\n",
      "Epoch 8/10\n",
      "708/708 [==============================] - 24s 33ms/step - loss: 0.1106 - accuracy: 0.9576 - val_loss: 0.2086 - val_accuracy: 0.9412\n",
      "Epoch 9/10\n",
      "708/708 [==============================] - 24s 34ms/step - loss: 0.0685 - accuracy: 0.9756 - val_loss: 0.1277 - val_accuracy: 0.9625\n",
      "Epoch 10/10\n",
      "708/708 [==============================] - 24s 34ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1548 - val_accuracy: 0.9617\n",
      "Accuracy: 0.9620029663111802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      6907\n",
      "           1       0.96      0.97      0.96      7252\n",
      "\n",
      "    accuracy                           0.96     14159\n",
      "   macro avg       0.96      0.96      0.96     14159\n",
      "weighted avg       0.96      0.96      0.96     14159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model = train_lstm(X_train_pad, y_train)\n",
    "evaluate_dl_model(lstm_model, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../classifiers/rf_model.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_model, '../classifiers/logisticregression.pkl')\n",
    "joblib.dump(nb_model, '../classifiers/naivebayes.pkl')\n",
    "joblib.dump(svm_model, '../classifiers/svm_model.pkl')\n",
    "joblib.dump(rf_model, '../classifiers/rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('../classifiers/cnn.h5')\n",
    "rnn_model.save('../classifiers/rnn.h5')\n",
    "lstm_model.save('../classifiers/lstm_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmachinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
