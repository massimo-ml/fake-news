{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_news.classifier_evaluation import evaluate_classifiers\n",
    "from fake_news.classifiers import (\n",
    "    ConvolutionalNeuralNetworkClassifier,\n",
    "    LogisticRegressionNewsClassifier,\n",
    "    LSTMClassifier,\n",
    "    MultinomialNaiveBayesClassifier,\n",
    "    RandomForestClassifierClass,\n",
    "    RecurrentNeuralNetworkClassifier,\n",
    "    SupportVectorMachineClassifier\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS_DICT = {\n",
    "    \"logistic\": (LogisticRegressionNewsClassifier, \"ml\"),\n",
    "    \"naive_bayes\": (MultinomialNaiveBayesClassifier, \"ml\"),\n",
    "    \"random_forest\": (RandomForestClassifierClass, \"ml\"),\n",
    "    \"svm\": (SupportVectorMachineClassifier, \"ml\"),\n",
    "    \"cnn\": (ConvolutionalNeuralNetworkClassifier, \"dl\"),\n",
    "    \"rnn\": (RecurrentNeuralNetworkClassifier, \"dl\"),\n",
    "    \"lstm\": (LSTMClassifier, \"dl\"),\n",
    "}\n",
    "\n",
    "ORIG_CLASSIFIER_PATHS_DICT = {\n",
    "    \"logistic\": R\"../fake_news/classifiers/logisticregression.pkl\",\n",
    "    \"naive_bayes\": R\"../fake_news/classifiers/naivebayes.pkl\",\n",
    "    \"random_forest\": R\"../fake_news/classifiers/rf_model.pkl\",\n",
    "    \"svm\": R\"../fake_news/classifiers/svm_model.pkl\",\n",
    "    \"cnn\": R\"../fake_news/classifiers/cnn.keras\",\n",
    "    \"rnn\": R\"../fake_news/classifiers/rnn.keras\",\n",
    "    \"lstm\": R\"../fake_news/classifiers/lstm_model.keras\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path(\"../data\")\n",
    "train_df = pd.read_csv(DATASET_DIR / \"WELFake_clean_train.csv\")\n",
    "test_df = pd.read_csv(DATASET_DIR / \"WELFake_clean_test.csv\")\n",
    "\n",
    "TOKENIZERS_DIR = Path(\"../fake_news/classifiers/tokenizers\")\n",
    "orig_tokenizer_paths = (\n",
    "    str(TOKENIZERS_DIR / \"ml_tokenizer.pickle\"),\n",
    "    str(TOKENIZERS_DIR / \"dl_tokenizer.pickle\") \n",
    ")\n",
    "synthetic_names = [\"tinyllama_real_articles.csv\"] ## CHANGE SYNTHETIC DATA HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading tokenizers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Started working on tinyllama_real_articles.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mamba\\envs\\fake-news\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\mamba\\envs\\fake-news\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "INFO:root:Started evaluating <class 'fake_news.classifiers.logisticRegression.LogisticRegressionNewsClassifier'>\n",
      "INFO:root:Fitting and predicting on original data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: ../fake_news/classifiers/logisticregression.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fitting and predicting on combined data\n",
      "INFO:root:Calculating metrics\n",
      "INFO:root:Started evaluating <class 'fake_news.classifiers.NaiveBayes.MultinomialNaiveBayesClassifier'>\n",
      "INFO:root:Fitting and predicting on original data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: ../fake_news/classifiers/naivebayes.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fitting and predicting on combined data\n",
      "INFO:root:Calculating metrics\n",
      "INFO:root:Started evaluating <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "INFO:root:Fitting and predicting on original data\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Started working on\u001b[39m\u001b[38;5;124m\"\u001b[39m, synthetic_name)\n\u001b[0;32m      9\u001b[0m synth_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATASET_DIR \u001b[38;5;241m/\u001b[39m synthetic_name)\n\u001b[1;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_classifiers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifiers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynth_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynth_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43morig_tokenizer_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_tokenizer_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombined_tokenizer_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_tokenizer_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43morig_classifier_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_classifier_paths\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m total_results[synthetic_name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     23\u001b[0m     classif_name: {\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morig\u001b[39m\u001b[38;5;124m\"\u001b[39m: classif_result[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[0;32m     30\u001b[0m }\n",
      "File \u001b[1;32md:\\Documents\\University\\Semester6\\NLP\\fake-news\\notebooks\\..\\fake_news\\classifier_evaluation.py:82\u001b[0m, in \u001b[0;36mevaluate_classifiers\u001b[1;34m(classifiers, train_df, synth_df, test_df, metrics, orig_tokenizer_paths, combined_tokenizer_paths, nltk_data_path, orig_classifier_paths)\u001b[0m\n\u001b[0;32m     78\u001b[0m     _fit_classifier(\n\u001b[0;32m     79\u001b[0m         orig_classifier, clf_type, orig_preprocessor, train_df\n\u001b[0;32m     80\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     \u001b[43morig_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m(orig_classifier_paths[i])\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m     84\u001b[0m orig_pred \u001b[38;5;241m=\u001b[39m _predict_classifier(\n\u001b[0;32m     85\u001b[0m     orig_classifier, clf_type, orig_preprocessor, test_df\n\u001b[0;32m     86\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "classifiers_to_evaluate = [\"logistic\", \"naive_bayes\", \"random_forest\", \"svm\"] ## CHANGE MODELS HERE\n",
    "classifiers = [CLASSIFIERS_DICT[name] for name in classifiers_to_evaluate]\n",
    "orig_classifier_paths = [ORIG_CLASSIFIER_PATHS_DICT[name] for name in classifiers_to_evaluate]\n",
    "\n",
    "total_results = {}\n",
    "\n",
    "for synthetic_name in synthetic_names:\n",
    "    print(\"=== Started working on\", synthetic_name)\n",
    "    synth_df = pd.read_csv(DATASET_DIR / synthetic_name)\n",
    "\n",
    "    results = evaluate_classifiers(\n",
    "        classifiers=classifiers, \n",
    "        train_df=train_df,\n",
    "        synth_df=synth_df,\n",
    "        test_df=test_df,\n",
    "        metrics=[\"acc\", \"auc\", \"f1\"],\n",
    "        orig_tokenizer_paths=orig_tokenizer_paths,\n",
    "        combined_tokenizer_paths=orig_tokenizer_paths,\n",
    "        orig_classifier_paths=orig_classifier_paths\n",
    "    )\n",
    "\n",
    "    total_results[synthetic_name] = {\n",
    "        classif_name: {\n",
    "            \"orig\": classif_result[0],\n",
    "            \"combined\": classif_result[1]\n",
    "        } \n",
    "        for classif_name, classif_result in zip(\n",
    "            classifiers_to_evaluate, results\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"total_results_1.json\", \"w\") as f:\n",
    "    json.dump(total_results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
