{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_news.classifier_evaluation import evaluate_classifiers\n",
    "from fake_news.classifiers import (\n",
    "    ConvolutionalNeuralNetworkClassifier,\n",
    "    LogisticRegressionNewsClassifier,\n",
    "    LSTMClassifier,\n",
    "    MultinomialNaiveBayesClassifier,\n",
    "    RandomForestClassifier,\n",
    "    RecurrentNeuralNetworkClassifier,\n",
    "    SupportVectorMachineClassifier\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS_DICT = {\n",
    "    \"logistic\": (LogisticRegressionNewsClassifier, \"ml\"),\n",
    "    \"naive_bayes\": (MultinomialNaiveBayesClassifier, \"ml\"),\n",
    "    \"random_forest\": (RandomForestClassifier, \"ml\"),\n",
    "    \"svm\": (SupportVectorMachineClassifier, \"ml\"),\n",
    "    \"cnn\": (ConvolutionalNeuralNetworkClassifier, \"dl\"),\n",
    "    \"rnn\": (RecurrentNeuralNetworkClassifier, \"dl\"),\n",
    "    \"lstm\": (LSTMClassifier, \"dl\"),\n",
    "}\n",
    "\n",
    "ORIG_CLASSIFIER_PATHS_DICT = {\n",
    "    \"logistic\": R\"../fake_news/classifiers/logisticregression.pkl\",\n",
    "    \"naive_bayes\": R\"../fake_news/classifiers/naivebayes.pkl\",\n",
    "    \"random_forest\": R\"../fake_news/classifiers/rf_model.pkl\",\n",
    "    \"svm\": R\"../fake_news/classifiers/svm_model.pkl\",\n",
    "    \"cnn\": R\"../fake_news/classifiers/cnn.keras\",\n",
    "    \"rnn\": R\"../fake_news/classifiers/rnn.keras\",\n",
    "    \"lstm\": R\"../fake_news/classifiers/lstm_model.keras\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path(\"../data\")\n",
    "train_df = pd.read_csv(DATASET_DIR / \"WELFake_clean_train.csv\")\n",
    "test_df = pd.read_csv(DATASET_DIR / \"WELFake_clean_test.csv\")\n",
    "\n",
    "TOKENIZERS_DIR = Path(\"../fake_news/classifiers/tokenizers\")\n",
    "orig_tokenizer_paths = (\n",
    "    str(TOKENIZERS_DIR / \"ml_tokenizer.pickle\"),\n",
    "    str(TOKENIZERS_DIR / \"dl_tokenizer.pickle\") \n",
    ")\n",
    "synthetic_names = [\"tinyllama_real_articles.csv\"] ## CHANGE SYNTHETIC DATA HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading tokenizers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Started working on tinyllama_real_articles.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mamba\\envs\\fake-news\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\mamba\\envs\\fake-news\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "INFO:root:Started evaluating <class 'fake_news.classifiers.logisticRegression.LogisticRegressionNewsClassifier'>\n",
      "INFO:root:Fitting and predicting on original data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: ../fake_news/classifiers/logisticregression.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fitting and predicting on combined data\n",
      "INFO:root:Calculating metrics\n",
      "INFO:root:Started evaluating <class 'fake_news.classifiers.NaiveBayes.MultinomialNaiveBayesClassifier'>\n",
      "INFO:root:Fitting and predicting on original data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: ../fake_news/classifiers/naivebayes.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fitting and predicting on combined data\n"
     ]
    }
   ],
   "source": [
    "classifiers_to_evaluate = [\"logistic\", \"naive_bayes\", \"random_forest\", \"svm\"] ## CHANGE MODELS HERE\n",
    "classifiers = [CLASSIFIERS_DICT[name] for name in classifiers_to_evaluate]\n",
    "orig_classifier_paths = [ORIG_CLASSIFIER_PATHS_DICT[name] for name in classifiers_to_evaluate]\n",
    "\n",
    "total_results = {}\n",
    "\n",
    "for synthetic_name in synthetic_names:\n",
    "    print(\"=== Started working on\", synthetic_name)\n",
    "    synth_df = pd.read_csv(DATASET_DIR / synthetic_name)\n",
    "\n",
    "    results = evaluate_classifiers(\n",
    "        classifiers=classifiers, \n",
    "        train_df=train_df,\n",
    "        synth_df=synth_df,\n",
    "        test_df=test_df,\n",
    "        metrics=[\"acc\", \"auc\", \"f1\"],\n",
    "        orig_tokenizer_paths=orig_tokenizer_paths,\n",
    "        combined_tokenizer_paths=orig_tokenizer_paths,\n",
    "        orig_classifier_paths=orig_classifier_paths\n",
    "    )\n",
    "\n",
    "    total_results[synthetic_name] = {\n",
    "        classif_name: {\n",
    "            \"orig\": classif_result[0],\n",
    "            \"combined\": classif_result[1]\n",
    "        } \n",
    "        for classif_name, classif_result in zip(\n",
    "            classifiers_to_evaluate, results\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"total_results_1.json\", \"w\") as f:\n",
    "    json.dump(total_results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
